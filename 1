import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,matthews_corrcoef,confusion_matrix, roc_curve, auc,roc_auc_score
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
# Load the dataset
data = pd.read_csv('Advertising.csv')

# Split data into features and target
X=data[['TV']];
6y=data['sales'];

threshold = y.median()  # Use the median as the threshold
y = (y > threshold).astype(int)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
-
# Train a logistic regression model
model = LogisticRegression(max_iter=10000,solver='liblinear')  # solver added for potential convergence issues
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Function to calculate custom metrics
def custom_metrics(y_true, y_pred):
    tp = np.sum((y_true == 1) & (y_pred == 1))
    fp = np.sum((y_true == 0) & (y_pred == 1))
    tn = np.sum((y_true == 0) & (y_pred == 0))
    fn = np.sum((y_true == 1) & (y_pred == 0))
    return tp, fp, tn, fn

tp, fp, tn, fn = custom_metrics(y_test, y_pred)
acc = (tp + tn) / (tp + tn + fp + fn)
precision = tp / (tp + fp)
recall = tp / (tp + fn)
f1 = 2 * (precision * recall) / (precision + recall)
mcc = ((tp * tn) - (fp * fn)) / np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))
specificity = tn / (tn + fp)
npv = tn / (tn + fn)

print(f'Accuracy: {acc}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}, MCC: {mcc}, Specificity: {specificity}, NPV: {npv}')


print('accuracy',accuracy_score(y_test,y_pred))
print('precision',precision_score(y_test,y_pred))
print('recall',recall_score(y_test,y_pred))
print('f1',f1_score(y_test,y_pred))
print('mcc',matthews_corrcoef(y_test,y_pred))

conf=confusion_matrix(y_test,y_pred);
print("Confusion matrix:\n",conf)
# ROC and AUC
y_proba = model.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_proba)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc='lower right')
plt.show()

print(f'AUC: {roc_auc}')

# *****************

roc_auc_model = roc_auc_score(y_test, y_proba)
 # Generate random probabilities and calculate AUC
random_probs = np.random.rand(len(y_test))
roc_auc_random = roc_auc_score(y_test, random_probs)
print(f"Model AUC: {roc_auc_model}")
print(f"Random AUC: {roc_auc_random}")


